<!DOCTYPE html>
<html lang="zh">
<head>
        <meta charset="utf-8" />
        <title>DaiweiWang@Github - Big Data</title>
        <link rel="stylesheet" href="https://wangdaiwei.github.io/theme/css/main.css" />
        <link href="https://wangdaiwei.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="DaiweiWang@Github Atom Feed" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://wangdaiwei.github.io/">DaiweiWang@Github </a></h1>
                <nav><ul>
                    <li><a href="https://wangdaiwei.github.io/category/development.html">Development</a></li>
                    <li><a href="https://wangdaiwei.github.io/category/math.html">Math</a></li>
                    <li><a href="https://wangdaiwei.github.io/category/misc.html">Misc</a></li>
                    <li><a href="https://wangdaiwei.github.io/category/study.html">Study</a></li>
                    <li><a href="https://wangdaiwei.github.io/category/unity.html">Unity</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="https://wangdaiwei.github.io/li-jie-hadoophe-mapreduce.html">理解Hadoop和MapReduce</a></h1>
<footer class="post-info">
        <abbr class="published" title="2014-01-25T00:00:00+08:00">
                Published: 周六 25 一月 2014
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="https://wangdaiwei.github.io/author/daiwei-wang.html">Daiwei Wang</a>
        </address>
<p>In <a href="https://wangdaiwei.github.io/category/study.html">Study</a>.</p>
<p>tags: <a href="https://wangdaiwei.github.io/tag/big-data.html">Big Data</a> </p>
</footer><!-- /.post-info --><h2>为什么需要用到Hadoop</h2>
<p>Hadoop是Apache开源基金会下的一个项目，针对处理大数据的特性设计的分布式编程模型工具。Hadoop的核心思想来源于Google的MapReduce和Google File System（GFS）。通俗来讲，就是将处理的问题分为两个子问题，一个负责将问题分割成一个一个小的部分，另一个负责将前一个步骤的每一部分都合并在一起。</p>
<p>最常见的例子就是单词统计。假设我们需要统计一个文档里的单词，最简单的方式就是用一个dictionary或者map来存储一个key-value对。一旦发现一个新的单词，我们就在这个dictionary里面添加一个条目，value设为1。如果这个单词已经存在，那么取出这个key对应的value，将其加1。这种方式对于一个小的文档来说固然合适，但如果我们处理的是一个TB，PB级别的数据呢？如果我们想在1秒钟之内就处理完这些数据？这就需要用到分布式处理了，也就是多台机器同时运算。对于数单词这样一个简单的工作，要解决的就是如何分配任务，每一台机器需要处理文档的哪个部分，以及如何将这些结果整合在一起。有了这样的思想，我们可以给这两个部分的工作分配给两个模块，一个是mapper，一个是reducer。mapper负责把问题分割成很小的一部分，每一部分都会产生一个问题的输出；reducer负责把所有若干个mapper产生的输出汇总，再计算出所需的输出。由于这种模型涉及到的数据量都比较大，而建立在大数据上的数据处理一般来说都相对比较简单，因此将这种模型一般化，使用户只需要关注mapper和reducer的具体实现，而不用考虑异常处理，问题分割等等细节问题，这就是Hadoop需要解决的问题。</p>
<p>但是，并不是所有问题都适合用MapReduce模型解决，比如说PageRank。当问题涉及到图结构的时候，一个很普遍的现象就是活跃节点和不活跃节点差异非常明显。比如说Yahoo网页的PageRank值要计算很多次才能收敛，因为它链接的网页实在是太多了。而小一点的网站可能一下子就收敛了，因为其本身链接的网站并不多，也并没有很高的影响力。而且在图问题中，绝大部分的节点都是不活跃的，也就是说可能整个MapReduce计算一次，只有少数几个节点的值发生了变化，这严重影响到了处理时间。Google针对这个问题提出了Pregel模型，GraphLab就是参考这个模型实现的，相关的论文里面可以看出在PageRank和三角形计数算法上GraphLab完胜基于MapReduce的Hadoop。</p>
<h2>理解Mapper和Reducer</h2>
<p>如果只从输入输出来看，mapper和reducer的输入输出都是一个key-valud对。当然，具体实现来说key和value并不是必须的，比如说统计所有文档的单词数，mapper的输入就可以是key：文件名，value：文件内容，文件名在这里不需要用到。</p>
<p>对于数单词这个问题，mapper需要做的就是把自己负责的那部分文档的单词都统计出来，输出key-value对。这里的key就是单词，value就是1，代表的含义就是在这部分的文档中这个单词出现了1次。当然，也可以在mapper里面就把所有重复的单词都统计一次，汇总之后再设为这个单词key的value。而reducer就会收到mapper的单词key-value对。假如一开始mapper输入的文档内容是这样的：</p>
<div class="highlight"><pre><span></span><span class="n">foo</span> <span class="n">other</span> <span class="n">more</span> <span class="n">data</span> <span class="n">foo</span>
</pre></div>


<p>那么mapper的输出就是如下形式：</p>
<div class="highlight"><pre><span></span><span class="n">foo</span> <span class="mi">1</span>
<span class="n">other</span> <span class="mi">1</span>
<span class="n">more</span> <span class="mi">1</span>
<span class="n">data</span> <span class="mi">1</span>
<span class="n">foo</span> <span class="mi">1</span>
</pre></div>


<p>此时reducer接收到的输入是按照key排列号的，因此实际上reducer的输入是如下的顺序输入的：</p>
<div class="highlight"><pre><span></span><span class="n">data</span> <span class="mi">1</span>
<span class="n">foo</span> <span class="mi">1</span>
<span class="n">foo</span> <span class="mi">1</span>
<span class="n">more</span> <span class="mi">1</span>
<span class="n">other</span> <span class="mi">1</span>
</pre></div>


<p>于是reducer可以这么写，这里用伪代码实现：</p>
<div class="highlight"><pre><span></span><span class="n">let</span> <span class="n">reduce</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">values</span><span class="p">)</span> <span class="o">=</span> 
    <span class="nb">sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">foreach</span> <span class="nb">int</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">vals</span><span class="p">:</span>
        <span class="nb">sum</span> <span class="o">+=</span> <span class="n">i</span>
    <span class="n">emit</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="nb">sum</span><span class="p">)</span>
</pre></div>


<p>这样得到的最终reducer的输出应该是这样的：</p>
<div class="highlight"><pre><span></span><span class="n">data</span> <span class="mi">1</span>
<span class="n">foo</span> <span class="mi">2</span>
<span class="n">more</span> <span class="mi">1</span>
<span class="n">other</span> <span class="mi">1</span>
</pre></div>


<h2>具体实现</h2>
<p>鉴于网上hadoop的教程都比较多，就不在这里写出来了，用Python实现的可以参考<a href="http://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/">Writing an Hadoop MapReduce Program in Python</a>，还有用Java实现的例子：<a href="http://www.cnblogs.com/xia520pi/archive/2012/06/04/2534533.html">Hadoop集群（第9期）_MapReduce初级案例</a>。</p><p>There are <a href="https://wangdaiwei.github.io/li-jie-hadoophe-mapreduce.html#disqus_thread">comments</a>.</p>                </article>
            </aside><!-- /#featured -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="http://jinja.pocoo.org/">Jinja2</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>
                            <li><a href="https://wangdaiwei.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate">atom feed</a></li>

                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46745526-1', 'auto');
    ga('send', 'pageview');
    </script>
<script type="text/javascript">
    var disqus_shortname = 'wangdaiwei-github';
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
</body>
</html>